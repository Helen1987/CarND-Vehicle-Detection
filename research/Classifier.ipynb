{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "vehicles_folder_path = os.path.join(project_dir, 'vehicles')\n",
    "nonvehicle_folder_path = os.path.join(project_dir, 'non-vehicles')\n",
    "\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "def read_images(collection, parent_folder, folder_name):\n",
    "    path = os.path.join(parent_folder, folder_name, '*.png')\n",
    "    images = glob.glob(path)\n",
    "    for image in images:\n",
    "        collection.append(image)\n",
    "\n",
    "def read_vehicle(folder_name):\n",
    "    read_images(cars, vehicles_folder_path, folder_name)\n",
    "    \n",
    "def read_nonvehicle(folder_name):\n",
    "    read_images(notcars, nonvehicle_folder_path, folder_name)\n",
    "\n",
    "# Read cars images\n",
    "read_vehicle('GTI_Far')\n",
    "read_vehicle('GTI_Left')\n",
    "read_vehicle('GTI_MiddleClose')\n",
    "read_vehicle('GTI_Right')\n",
    "read_vehicle('KITTI_extracted')\n",
    "    \n",
    "#read non-car images\n",
    "read_nonvehicle('Extras')\n",
    "read_nonvehicle('GTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.06 Seconds to extract Color and Space features...\n",
      "Using spatial binning of: 16 and 32 histogram bins\n",
      "Feature vector length: 864\n",
      "4.54 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9561\n",
      "My SVC predicts:  [ 0.  1.  1.  1.  0.  1.  0.  0.  0.  1.]\n",
      "For these 10 labels:  [ 0.  1.  1.  1.  0.  1.  0.  0.  0.  1.]\n",
      "0.001 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.FeatureExtractor import FeatureExtractor\n",
    "\n",
    "color_space = 'YCrCb'\n",
    "hist_range = (0, 256)\n",
    "spatial = 16\n",
    "histbin = 32\n",
    "\n",
    "t=time.time()\n",
    "car_features = FeatureExtractor.extract_features_from_images(cars, cspace=color_space, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=hist_range)\n",
    "notcar_features = FeatureExtractor.extract_features_from_images(notcars, cspace=color_space, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=hist_range)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract Color and Space features...')\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using spatial binning of:',spatial,\n",
    "    'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle is saved\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "to_save = {\n",
    "    'svc': svc,\n",
    "    'X_scaler': X_scaler,\n",
    "    'features': (1, 1, 0), # color, space, hog\n",
    "    'color_space': color_space,\n",
    "    'spatial': spatial,\n",
    "    'histbin': histbin,\n",
    "    'hist_range': hist_range\n",
    "}\n",
    "\n",
    "# save transformer\n",
    "with open(os.path.join(project_dir, 'sparse_color.pkl'), 'wb') as fid:\n",
    "    pickle.dump(to_save, fid) \n",
    "print(\"pickle is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.FeatureExtractor import FeatureExtractor\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "colorspace = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 7\n",
    "pix_per_cell = 4\n",
    "cell_per_block = 4\n",
    "hog_channel = 1 # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "t=time.time()\n",
    "car_features = FeatureExtractor.extract_hog_features(cars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_features = FeatureExtractor.extract_hog_features(notcars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "to_save = {\n",
    "    'svc': svc,\n",
    "    'X_scaler': X_scaler,\n",
    "    'features': (0, 0, 1), # color, space, hog\n",
    "    'color_space': color_space,\n",
    "    'orient': orient,\n",
    "    'pix_per_cell': pix_per_cell,\n",
    "    'cell_per_block': cell_per_block,\n",
    "    'hog_channel': hog_channel\n",
    "}\n",
    "\n",
    "# save the classifier\n",
    "with open(os.path.join(project_dir, 'hog.pkl'), 'wb') as fid:\n",
    "    pickle.dump(to_save, fid) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IntroToTensorFlow]",
   "language": "python",
   "name": "conda-env-IntroToTensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
